# The provider for the AI models to use.
MODEL_PROVIDER=ollama

# The name of LLM model to use.
MODEL=llama3.2:1b
OLLAMA_BASE_URL=http://localhost:11434

# Name of the embedding model to use.
EMBEDDING_MODEL=BAAI/bge-base-en-v1.5

# Dimension of the embedding model to use.
EMBEDDING_DIM=768

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
# OPENAI_API_KEY=

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
# TOP_K=

# PostGreSQL database URL.
PG_CONNECTION_STRING="postgresql://postgres:password@localhost:5432/metanavit"
PSYCOPG2_CONNECTION_STRING="dbname=metanavit user=postgres password=password host=localhost port=5432"
DB_NAME="metanavit"

# Storage management
FRONTEND_DIR=".frontend"
STATIC_DIR="static"
DATA_DIR="datasets/Easy/category_organization"
STORAGE_DIR="storage"


# The directory to store the local storage cache.
STORAGE_CACHE_DIR=.cache

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:8000/api/files

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant! Your task is to suggest the next question that user might ask. 
Here is the conversation history
---------------------
{conversation}
---------------------
Given the conversation history, please give me 3 questions that user might ask next!
Your answer should be wrapped in three sticks which follows the following format:
```
<question 1>
<question 2>
<question 3>
```"

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a helpful AI assistant. For questions requiring specific knowledge, use the query engine tool to search the knowledge base. Only use query index tool"
